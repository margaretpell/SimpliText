{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w4QZ0CCA4yZ",
        "outputId": "3d157054-33a0-4ad7-d431-9a1bd647e5a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wordfreq in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: ftfy>=6.1 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (6.1.3)\n",
            "Requirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (3.3.0)\n",
            "Requirement already satisfied: locate<2.0.0,>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (1.1.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (1.0.7)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (2023.10.3)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1->wordfreq) (0.2.12)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.3.7)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wordfreq\n",
        "from wordfreq import word_frequency\n",
        "import spacy\n",
        "!pip install openai\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tadY-rixBIVU"
      },
      "outputs": [],
      "source": [
        "def explain_sentences(statement):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4-1106-preview\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a helpful assistant.\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Explain the following sentences. Only give me your explanation in a paragraph. Do not involve original sentences: {statement}\",\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.5,\n",
        "        top_p=0.5,\n",
        "    )\n",
        "    return completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sJhHQi5IBRF7"
      },
      "outputs": [],
      "source": [
        "def examples(sentence):\n",
        "    completion = client.chat.completions.create(\n",
        "      model='gpt-4-1106-preview',\n",
        "      messages=[\n",
        "        {\"role\": \"system\",\n",
        "         \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": f\"Add one concise sentence of example if it has, to {sentence} for better understanding. Give me the sentences after adding this example.\"}\n",
        "      ],\n",
        "      temperature=0.5,\n",
        "      top_p=0.5\n",
        "    )\n",
        "    return completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SjJoTUKmBbTl"
      },
      "outputs": [],
      "source": [
        "def check_freq(sentence):\n",
        "\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  words = [tok.lemma_ for tok in nlp(sentence) if tok.pos_ not in [\"PUNCT\", \"SPACE\"]]\n",
        "\n",
        "  freq_dict = {}\n",
        "  for word in words:\n",
        "    freq = word_frequency(word, 'en')\n",
        "    freq_dict[word] = freq\n",
        "\n",
        "  vocab = dict(sorted(freq_dict.items(), key=lambda item: item[1]))\n",
        "  return vocab\n",
        "\n",
        "def words_exp(sentence):\n",
        "\n",
        "  freq_dict = check_freq(sentence)\n",
        "\n",
        "  explain = dict((k, v) for k, v in freq_dict.items() if v < 1e-4)\n",
        "\n",
        "  words = list(explain.keys())\n",
        "\n",
        "  return words\n",
        "\n",
        "def explain_words(sentence):\n",
        "  words = words_exp(sentence)\n",
        "  assis = 'Give me a new verison of sentences which correctly explain these words in simpler sentences or correctly paraphrase with super easy-to-understand words(consider their academic meaning if neccesary):'\n",
        "  for word in words:\n",
        "    assis += word\n",
        "    assis += ', '\n",
        "  assis += 'inside sentences and only give me the new version of explained sentences.'\n",
        "\n",
        "  completion = client.chat.completions.create(\n",
        "      model='gpt-4-1106-preview',\n",
        "      messages=[\n",
        "         {\"role\": \"system\",\n",
        "         \"content\": assis},\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": sentence}\n",
        "      ],\n",
        "      temperature=0.5,\n",
        "      top_p=0.5,\n",
        "  )\n",
        "\n",
        "  return completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hI71hCY8BlMW"
      },
      "outputs": [],
      "source": [
        "def simplify_structure(sentence):\n",
        "  completion = client.chat.completions.create(\n",
        "      model='gpt-4-1106-preview',\n",
        "      messages=[\n",
        "        {\"role\": \"system\",\n",
        "         \"content\": \"Break all sentences into simple sentences without missing any important details and ensure the sentences are readable and coherent. Also do not increase words' complexity, do not give me several points but a coherent paragraph.\"},\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": sentence}\n",
        "      ],\n",
        "      temperature=0.5,\n",
        "      top_p=0.5,\n",
        "  )\n",
        "  return completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wZrgUVJPB2Ed"
      },
      "outputs": [],
      "source": [
        "def explain(sent):\n",
        "  tmp = explain_sentences(sent)\n",
        "  tmp2 = examples(tmp)\n",
        "  tmp3 = explain_words(tmp2)\n",
        "  tmp4 = simplify_structure(tmp3)\n",
        "  result = explain_words(tmp4)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "id": "xTPof6ACB_2J",
        "outputId": "199fc702-b51e-4346-c567-10c3375a2a7c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Edwards thinks that slight shifts in warmth from the sun can change our planet. These shifts come from space patterns called Milankovitch cycles. The Earth's weather system, which includes loops that can make these shifts stronger or weaker, intensifies these changes. These loops are called feedback loops. They can make the sun's warmth changes more or less powerful, causing big weather changes. For instance, when there's less ice, the sea soaks up more warmth. This soaking up can cause even more ice to melt. Edwards hints that we might not see these changes from the sun right away, but they really do shake up our weather. This shake-up happens because of natural processes in the world around us.\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "explain(\"However, Edwards believes the small changes in solar heating produced by Milankovitch cycles are then amplified by feedback mechanisms on Earth.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "id": "6Ag6RfZxERx_",
        "outputId": "033fd2e7-1c06-4051-ff97-6b5ca83538b7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Ehrlich has a theory about how things work together. Changes in heat or cold happen often. Normally, these changes even out. They act against each other. But sometimes, these changes can join forces. When they join, their effect gets stronger. For example, warm air can mix with a lot of air pressure. This mix can make a really hot time. When this mix happens, the change in heat is big. The change doesn't go away fast. It makes the heat stay different for a long time. Ehrlich's theory points out that in systems that are always changing, certain mixes can cause big and long-lasting changes in heat. These changes are not like the short changes that usually happen.\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "explain(\"Ehrlich's model shows that whilst most of these oscillations cancel each other out, some reinforce one another and become long-lived temperature variations.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUg-HOp8F9dG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('data.csv')\n",
        "df = df.reset_index(drop=True)\n",
        "original = df[df.columns[0]].tolist()\n",
        "results = []\n",
        "for statement in original:\n",
        "    exp = explain(statement)\n",
        "    results.append(exp)\n",
        "\n",
        "df_combined = pd.DataFrame({\n",
        "    'OriginalStatements': original,\n",
        "    'ExplainedStatements': results,\n",
        "})\n",
        "\n",
        "df_combined.to_csv('explanation.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
