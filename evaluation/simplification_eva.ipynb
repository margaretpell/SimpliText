{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CX8USzH3hR8",
        "outputId": "a8d0b1f5-a753-48d5-e946-d0c030a60c34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wordfreq in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: ftfy>=6.1 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (6.1.1)\n",
            "Requirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (3.3.0)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (1.0.7)\n",
            "Requirement already satisfied: regex>=2021.7.6 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (2023.6.3)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1->wordfreq) (0.2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install wordfreq\n",
        "from wordfreq import word_frequency\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_freq(sentence):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  words = [tok.lemma_ for tok in nlp(sentence) if tok.pos_ not in [\"PUNCT\", \"SPACE\"]]\n",
        "  freq_dict = {}\n",
        "  for word in words:\n",
        "    freq = word_frequency(word, 'en')\n",
        "    freq_dict[word] = freq\n",
        "  vocab = dict(sorted(freq_dict.items(), key=lambda item: item[1]))\n",
        "  return vocab"
      ],
      "metadata": {
        "id": "c8q0eR6T3wM_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Words Frequency\n",
        "import pandas as pd\n",
        "def compare_sentence_freq(sentence1, sentence2):\n",
        "    freq_dict1 = check_freq(sentence1)\n",
        "    freq_dict2 = check_freq(sentence2)\n",
        "    low_freq_count1 = sum(1 for freq in freq_dict1.values() if freq < 1e-4)\n",
        "    low_freq_count2 = sum(1 for freq in freq_dict2.values() if freq < 1e-4)\n",
        "    return 0 if low_freq_count1 > low_freq_count2 else 1\n",
        "\n",
        "def compare_min_word_freq(sentence1, sentence2):\n",
        "    freq_dict1 = check_freq(sentence1)\n",
        "    freq_dict2 = check_freq(sentence2)\n",
        "    min_freq1 = min(freq_dict1.values()) if freq_dict1 else float('inf')\n",
        "    min_freq2 = min(freq_dict2.values()) if freq_dict2 else float('inf')\n",
        "    return 0 if min_freq1 < min_freq2 else 1\n",
        "\n",
        "df_simplification = pd.read_csv('simplification.csv')\n",
        "df_baseline = pd.read_csv('baseline.csv')\n",
        "count_compare_sentence_freq = 0\n",
        "count_compare_min_word_freq = 0\n",
        "for (sentence1, sentence2) in zip(df_simplification.iloc[:, 1], df_baseline.iloc[:, 1]):\n",
        "    count_compare_sentence_freq += compare_sentence_freq(sentence1, sentence2)\n",
        "    count_compare_min_word_freq += compare_min_word_freq(sentence1, sentence2)\n",
        "\n",
        "rate_compare_sentence_freq = count_compare_sentence_freq / len(df_simplification)\n",
        "rate_compare_min_word_freq = count_compare_min_word_freq / len(df_simplification)\n",
        "print(\"Sucess rate for compare_sentence_freq:\", rate_compare_sentence_freq)\n",
        "print(\"Sucess rate for compare_min_word_freq:\", rate_compare_min_word_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-L-emcT30Fd",
        "outputId": "d20d902c-f455-4654-8551-c8fa22e57cf1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sucess rate for compare_sentence_freq: 0.8686868686868687\n",
            "Sucess rate for compare_min_word_freq: 0.8686868686868687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def average_sentence_length(text):\n",
        "    sentences = text.split('.')\n",
        "    word_counts = [len(sentence.split()) for sentence in sentences if sentence.strip()]\n",
        "    if len(word_counts) == 0:\n",
        "        return 0\n",
        "    return sum(word_counts) / len(word_counts)"
      ],
      "metadata": {
        "id": "Y6fy9YTn7vzL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Sentence Length\n",
        "def compare_average_sentence_length(sentence1, sentence2):\n",
        "    avg_len1 = average_sentence_length(sentence1)\n",
        "    avg_len2 = average_sentence_length(sentence2)\n",
        "    return 0 if avg_len1 > avg_len2 else 1\n",
        "\n",
        "df_simplification = pd.read_csv('simplification.csv')\n",
        "df_baseline = pd.read_csv('baseline.csv')\n",
        "results = [compare_average_sentence_length(sentence1, sentence2)\n",
        "           for sentence1, sentence2 in zip(df_simplification.iloc[:, 1], df_baseline.iloc[:, 1])]\n",
        "rate_of_1 = sum(results) / len(results)\n",
        "print(\"Sucess rate:\", rate_of_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYlBDpvU8jYq",
        "outputId": "399b16eb-ede6-4e6a-bc8d-e5c8bb2dde4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sucess rate: 0.9696969696969697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Readability\n",
        "!pip install textstat\n",
        "import textstat\n",
        "import pandas as pd\n",
        "\n",
        "def compare_readability(sentence1, sentence2):\n",
        "    score1 = textstat.flesch_kincaid_grade(sentence1)\n",
        "    score2 = textstat.flesch_kincaid_grade(sentence2)\n",
        "    return 0 if score1 > score2 else 1\n",
        "\n",
        "df_simplification = pd.read_csv('simplification.csv')\n",
        "df_baseline = pd.read_csv('baseline.csv')\n",
        "results = [compare_readability(sentence1, sentence2)\n",
        "           for sentence1, sentence2 in zip(df_simplification.iloc[:, 1], df_baseline.iloc[:, 1])]\n",
        "rate_of_1 = sum(results) / len(results)\n",
        "print(\"Sucess rate:\", rate_of_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqlW0pZd9PHG",
        "outputId": "2d5942b5-54f6-4f36-a783-2fccd4f7ef0d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textstat in /usr/local/lib/python3.10/dist-packages (0.7.3)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.10/dist-packages (from textstat) (0.14.0)\n",
            "Sucess rate: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Lexical Diversity\n",
        "from lexicalrichness import LexicalRichness\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_lexical_diversity_measures(sentence):\n",
        "    lex = LexicalRichness(sentence)\n",
        "    hdd_draws = min(lex.words, 50)\n",
        "    return {\n",
        "        'ttr': lex.ttr,  # Type-Token Ratio\n",
        "        'hdd': lex.hdd(draws=hdd_draws) if lex.words > 0 else 0 # HDD with draws\n",
        "    }\n",
        "\n",
        "def compare_lexical_diversity(sentence1, sentence2, measure):\n",
        "    diversity1 = calculate_lexical_diversity_measures(sentence1)\n",
        "    diversity2 = calculate_lexical_diversity_measures(sentence2)\n",
        "    return 0 if diversity1[measure] > diversity2[measure] else 1\n",
        "\n",
        "df_simplification = pd.read_csv('simplification.csv')\n",
        "df_baseline = pd.read_csv('baseline.csv')\n",
        "measures = ['ttr', 'hdd']\n",
        "for measure in measures:\n",
        "    results = [compare_lexical_diversity(sentence1, sentence2, measure)\n",
        "               for sentence1, sentence2 in zip(df_simplification.iloc[:, 1], df_baseline.iloc[:, 1])]\n",
        "    rate_of_1 = sum(results) / len(results)\n",
        "    print(f\"Sucess rate for {measure.upper()}: {rate_of_1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFcJJuS0ENuo",
        "outputId": "25601a75-927c-4acf-df1c-1bdf0f6deae8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sucess rate for TTR: 0.8181818181818182\n",
            "Sucess rate for HDD: 0.797979797979798\n"
          ]
        }
      ]
    }
  ]
}
