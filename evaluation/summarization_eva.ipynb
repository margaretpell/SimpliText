{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CX8USzH3hR8",
        "outputId": "a59fa1ea-1425-4603-d627-41285587b440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wordfreq in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: ftfy>=6.1 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (6.1.3)\n",
            "Requirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (3.3.0)\n",
            "Requirement already satisfied: locate<2.0.0,>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (1.1.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (1.0.7)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.10/dist-packages (from wordfreq) (2023.10.3)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1->wordfreq) (0.2.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install wordfreq\n",
        "from wordfreq import word_frequency\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_freq(sentence):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  words = [tok.lemma_ for tok in nlp(sentence) if tok.pos_ not in [\"PUNCT\", \"SPACE\"]]\n",
        "  freq_dict = {}\n",
        "  for word in words:\n",
        "    freq = word_frequency(word, 'en')\n",
        "    freq_dict[word] = freq\n",
        "  vocab = dict(sorted(freq_dict.items(), key=lambda item: item[1]))\n",
        "  return vocab"
      ],
      "metadata": {
        "id": "c8q0eR6T3wM_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Words Frequency\n",
        "import pandas as pd\n",
        "def compare_sentence_freq(sentence1, sentence2):\n",
        "    freq_dict1 = check_freq(sentence1)\n",
        "    freq_dict2 = check_freq(sentence2)\n",
        "    low_freq_count1 = sum(1 for freq in freq_dict1.values() if freq < 1e-4)\n",
        "    low_freq_count2 = sum(1 for freq in freq_dict2.values() if freq < 1e-4)\n",
        "    return 0 if low_freq_count1 > low_freq_count2 else 1\n",
        "\n",
        "def compare_min_word_freq(sentence1, sentence2):\n",
        "    freq_dict1 = check_freq(sentence1)\n",
        "    freq_dict2 = check_freq(sentence2)\n",
        "    min_freq1 = min(freq_dict1.values()) if freq_dict1 else float('inf')\n",
        "    min_freq2 = min(freq_dict2.values()) if freq_dict2 else float('inf')\n",
        "    return 0 if min_freq1 < min_freq2 else 1\n",
        "\n",
        "df_sum = pd.read_csv('summarization.csv')\n",
        "df_baseline = pd.read_csv('baseline.csv')\n",
        "count_compare_sentence_freq = 0\n",
        "count_compare_min_word_freq = 0\n",
        "for (sentence1, sentence2) in zip(df_sum.iloc[:, 1], df_baseline.iloc[:, 2]):\n",
        "    count_compare_sentence_freq += compare_sentence_freq(sentence1, sentence2)\n",
        "    count_compare_min_word_freq += compare_min_word_freq(sentence1, sentence2)\n",
        "\n",
        "rate_compare_sentence_freq = count_compare_sentence_freq / len(df_sum)\n",
        "rate_compare_min_word_freq = count_compare_min_word_freq / len(df_sum)\n",
        "print(\"Sucess rate for compare_sentence_freq:\", rate_compare_sentence_freq)\n",
        "print(\"Sucess rate for compare_min_word_freq:\", rate_compare_min_word_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-L-emcT30Fd",
        "outputId": "3ca8e50c-4f0a-42de-f74c-b80577251c1c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sucess rate for compare_sentence_freq: 0.9393939393939394\n",
            "Sucess rate for compare_min_word_freq: 0.8585858585858586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def average_sentence_length(text):\n",
        "    sentences = text.split('.')\n",
        "    word_counts = [len(sentence.split()) for sentence in sentences if sentence.strip()]\n",
        "    if len(word_counts) == 0:\n",
        "        return 0\n",
        "    return sum(word_counts) / len(word_counts)"
      ],
      "metadata": {
        "id": "Y6fy9YTn7vzL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Sentence Length\n",
        "def compare_average_sentence_length(sentence1, sentence2):\n",
        "    avg_len1 = average_sentence_length(sentence1)\n",
        "    avg_len2 = average_sentence_length(sentence2)\n",
        "    return 0 if avg_len1 > avg_len2 else 1\n",
        "df_sum = pd.read_csv('summarization.csv')\n",
        "df_baseline = pd.read_csv('baseline.csv')\n",
        "results = [compare_average_sentence_length(sentence1, sentence2)\n",
        "           for sentence1, sentence2 in zip(df_sum.iloc[:, 1], df_baseline.iloc[:, 2])]\n",
        "rate_of_1 = sum(results) / len(results)\n",
        "print(\"Sucess rate:\", rate_of_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYlBDpvU8jYq",
        "outputId": "3f99f184-badb-492c-a8a9-6ff438a68c83"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sucess rate: 0.7878787878787878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def total_sentence_length(text):\n",
        "    sentences = text.split('.')\n",
        "    word_counts = [len(sentence.split()) for sentence in sentences if sentence.strip()]\n",
        "    return sum(word_counts)\n",
        "\n",
        "# Function to compare the total sentence lengths of two texts\n",
        "def compare_total_sentence_length(text1, text2):\n",
        "    total_len1 = total_sentence_length(text1)\n",
        "    total_len2 = total_sentence_length(text2)\n",
        "    return 0 if total_len1 > total_len2 else 1\n",
        "\n",
        "df_sum = pd.read_csv('summarization.csv')\n",
        "df_baseline = pd.read_csv('baseline.csv')\n",
        "\n",
        "# Compare the total sentence lengths and calculate the rate of texts with shorter lengths\n",
        "results = [compare_total_sentence_length(text1, text2)\n",
        "           for text1, text2 in zip(df_sum.iloc[:, 1], df_baseline.iloc[:, 2])]\n",
        "rate_of_1 = sum(results) / len(results)\n",
        "print(\"Success rate:\", rate_of_1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0kalSu9q2sG",
        "outputId": "fa2dacbc-4b05-4b26-a5e2-667e56058af7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success rate: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Readability\n",
        "!pip install textstat\n",
        "import textstat\n",
        "import pandas as pd\n",
        "\n",
        "def compare_readability(sentence1, sentence2):\n",
        "    score1 = textstat.flesch_kincaid_grade(sentence1)\n",
        "    score2 = textstat.flesch_kincaid_grade(sentence2)\n",
        "    return 0 if score1 > score2 else 1\n",
        "\n",
        "df_sum = pd.read_csv('summarization.csv')\n",
        "df_baseline = pd.read_csv('baseline.csv')\n",
        "results = [compare_readability(sentence1, sentence2)\n",
        "           for sentence1, sentence2 in zip(df_sum.iloc[:, 1], df_baseline.iloc[:, 2])]\n",
        "rate_of_1 = sum(results) / len(results)\n",
        "print(\"Sucess rate:\", rate_of_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqlW0pZd9PHG",
        "outputId": "9bddfd73-3674-46fd-fb4d-789d3a6117ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textstat in /usr/local/lib/python3.10/dist-packages (0.7.3)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.10/dist-packages (from textstat) (0.14.0)\n",
            "Sucess rate: 0.6161616161616161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Manully Evaluation Methods\n",
        "##1. Key points: Both did well\n",
        "##2. Non-Redundancy: Our model reaches success rate of 1.0\n",
        "##3. Fidelity to Original Intent: Both did well\n",
        "##4. Scores for two summarization version: Our model reaches success rate of 0.92\n",
        "### In conclusion, our model performs better in summarization."
      ],
      "metadata": {
        "id": "zATSMiSSwWPI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
